{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"dark\")\n",
    "sns.set_palette(\"GnBu_d\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/numerical.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking which columns aren't null\n",
    "df.columns[~df.isna().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "basically all the financial data has missing values somewhere that needs to be further analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_columns = df.columns[df.isna().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[null_columns].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the proportion of missing values per feature\n",
    "missing_proportions = df[null_columns].isna().mean()\n",
    "missing_proportions = missing_proportions.sort_values(ascending=False)\n",
    "missing_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(missing_proportions[missing_proportions > 0.7].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out features with more than 50% missing values\n",
    "df_dropped = df.drop(missing_proportions[missing_proportions > 0.5].index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5% missing data\n",
    "missing_proportions[missing_proportions <= 0.05].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped.groupby('Ticker').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward fill the remaining missing values (temporary bandaid fix for all features, could be perma for some)\n",
    "df_dropped = df_dropped.fillna(method='bfill', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped[null_columns.intersection(df_dropped.columns)].isna().sum()[df_dropped[null_columns.intersection(df_dropped.columns)].isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_counts = df.groupby('Date').size().reset_index(name='count')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = sns.color_palette(\"GnBu_d\", len(date_counts))\n",
    "sns.barplot(data=date_counts, x='Date', y='count', palette=colors, hue='Date', legend=False)\n",
    "\n",
    "plt.xticks(rotation=90) \n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Data Points\")\n",
    "plt.title(\"Data Count Per Record Date\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_counts = df.groupby('ratingYear').size().reset_index(name='count')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors = sns.color_palette(\"GnBu_d\", len(date_counts))\n",
    "sns.barplot(data=date_counts, x='ratingYear', y='count', palette=colors, hue='ratingYear', legend=False)\n",
    "\n",
    "plt.xticks(rotation=90) \n",
    "plt.xlabel(\"ratingYear\")\n",
    "plt.ylabel(\"Data Points\")\n",
    "plt.title(\"Data Count Per ESG Rating Year\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important financial feature extracted based on domain knowledge\n",
    "financial_features = [\n",
    "    'EBITDA',\n",
    "    'EBIT',\n",
    "    'Total Expenses',\n",
    "    'Diluted EPS',\n",
    "    'Basic EPS',\n",
    "    'Net Income',\n",
    "    'Operating Income',\n",
    "    'Operating Expense',\n",
    "    'Gross Profit',\n",
    "    'Cost Of Revenue',\n",
    "    'Total Revenue',\n",
    "    'Total Debt',\n",
    "    'Net Debt',\n",
    "    'Working Capital',\n",
    "    'Total Assets',\n",
    "    'Stockholders Equity',\n",
    "    'Total Expenses',\n",
    "    'Operating Cash Flow',\n",
    "    'Free Cash Flow',\n",
    "    'Capital Expenditure',\n",
    "    'Research And Development',\n",
    "    'Common Stock Dividend Paid',\n",
    "    'Ordinary Shares Number',\n",
    "    'Current Assets',\n",
    "    'Current Liabilities',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features = [\n",
    "    'Ticker',\n",
    "    'Date',\n",
    "    'totalEsg',\n",
    "    'ratingDate',\n",
    "    'environtmentScore',\n",
    "    'socialScore',\n",
    "    'governanceScore',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking data types & distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[financial_features].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = financial_features[0]\n",
    "print(f\"Feature: {feature}\")\n",
    "sns.histplot(df[feature], kde=True)\n",
    "plt.title(f\"Distribution of {feature}\")\n",
    "plt.xlim(0, df[feature].quantile(0.90)) # used to remove outliers\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in financial_features:\n",
    "    print(f\"\\nFeature: {feature}\")\n",
    "    sns.histplot(df[feature], kde=True)\n",
    "    plt.title(f\"Distribution of {feature}\")\n",
    "    plt.xlim(0, df[feature].quantile(0.90))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying out log transformations to handle skewedness\n",
    "df[\"Basic_EPS_Log\"] = np.log1p(df[\"Basic EPS\"])  # log1p avoids log(0) errors\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df[\"Basic_EPS_Log\"], kde=True, bins=30)\n",
    "plt.title(\"Log-Transformed Distribution of Basic EPS\")\n",
    "plt.xlabel(\"Log(Basic EPS)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying out robust scaling to handle skewedness\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "df[\"Basic_EPS_Scaled\"] = scaler.fit_transform(df[[\"Basic EPS\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df[\"Basic_EPS_Scaled\"], kde=True, bins=30)\n",
    "plt.title(\"Robust Scaled Distribution of Basic EPS\")\n",
    "plt.xlim(0, df[\"Basic_EPS_Scaled\"].quantile(0.99))\n",
    "plt.xlabel(\"Basic EPS (Robust Scaled)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Feature Relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Redundant Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multicollinearity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair Plots & Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esg_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
